"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[258],{1709:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var n=i(4848),a=i(8453);const o={slug:"welcome",title:"LHCb and DIRAC Strategy Towards the LHCb Upgrade",authors:["fstagni","atsar","chaen","pchar","zmathe","wkrz","vroman"],tags:["dirac","lhcb","paper"]},r=void 0,s={permalink:"/diracx/blog/welcome",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-08-17.md",source:"@site/blog/2019-08-17.md",title:"LHCb and DIRAC Strategy Towards the LHCb Upgrade",description:"The DIRAC project is developing interware to build and operate distributed computing systems. It provides a development framework and a rich set of services for both Workload and Data Management tasks of large scientific communities. DIRAC is adopted by a growing number of collaborations, including LHCb, Belle2, CLIC, and CTA. The LHCb experiment will be upgraded during the second long LHC shutdown (2019-2020). At restart of data taking in Run 3, the instantaneous luminosity will increase by a factor of five. The LHCb computing model also need be upgraded. Oversimplifying, this translates into the need for significantly more computing power and resources, and more storage with respect to what LHCb uses right now. The DIRAC interware will keep being the tool to handle all of LHCb distributed computing resources. Within this contribution, we highlight the ongoing and planned efforts to ensure that DIRAC will be able to provide an optimal usage of its distributed computing resources. This contribution focuses on DIRAC plans for increasing the scalability of the overall system, taking in consideration that the main requirement is keeping a running system working. This requirement translates into the need of studies and developments within the current DIRAC architecture. We believe that scalability is about traffic growth, dataset growth, and maintainability: within this contribution we address all of them, showing the technical solutions we are adopting.",date:"2019-08-17T00:00:00.000Z",tags:[{inline:!1,label:"DIRAC",permalink:"/diracx/blog/tags/dirac",description:"DIRAC tag description"},{inline:!1,label:"LHCb",permalink:"/diracx/blog/tags/lhcb",description:"LHCb tag description"},{inline:!1,label:"Paper",permalink:"/diracx/blog/tags/paper",description:"Paper tag description"}],readingTime:1.145,hasTruncateMarker:!1,authors:[{name:"Federico Stagni",title:"CERN",key:"fstagni"},{name:"Andrei Tsaregorodtsev",title:"CERN",key:"atsar"},{name:"Christophe Haen",key:"chaen"},{name:"Philippe Charpentier",key:"pchar"},{name:"Zoltan Mathe",key:"zmathe"},{name:"Wojciech Jan Krzemien",key:"wkrz"},{name:"Vladimir Romanovski",key:"vroman"}],frontMatter:{slug:"welcome",title:"LHCb and DIRAC Strategy Towards the LHCb Upgrade",authors:["fstagni","atsar","chaen","pchar","zmathe","wkrz","vroman"],tags:["dirac","lhcb","paper"]},unlisted:!1,prevItem:{title:"The 10th DIRAC Users' Workshop: 19th-21st June 2024, Lyon (FR)",permalink:"/diracx/blog/10thworkshop"},nextItem:{title:"DIRAC\u2014The Distributed MC Production and Analysis for LHCb",permalink:"/diracx/blog/dirac-2004"}},c={authorsImageUrls:[void 0,void 0,void 0,void 0,void 0,void 0,void 0]},l=[];function d(e){const t={a:"a",p:"p",...(0,a.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.p,{children:"The DIRAC project is developing interware to build and operate distributed computing systems. It provides a development framework and a rich set of services for both Workload and Data Management tasks of large scientific communities. DIRAC is adopted by a growing number of collaborations, including LHCb, Belle2, CLIC, and CTA. The LHCb experiment will be upgraded during the second long LHC shutdown (2019-2020). At restart of data taking in Run 3, the instantaneous luminosity will increase by a factor of five. The LHCb computing model also need be upgraded. Oversimplifying, this translates into the need for significantly more computing power and resources, and more storage with respect to what LHCb uses right now. The DIRAC interware will keep being the tool to handle all of LHCb distributed computing resources. Within this contribution, we highlight the ongoing and planned efforts to ensure that DIRAC will be able to provide an optimal usage of its distributed computing resources. This contribution focuses on DIRAC plans for increasing the scalability of the overall system, taking in consideration that the main requirement is keeping a running system working. This requirement translates into the need of studies and developments within the current DIRAC architecture. We believe that scalability is about traffic growth, dataset growth, and maintainability: within this contribution we address all of them, showing the technical solutions we are adopting."}),"\n",(0,n.jsxs)(t.p,{children:["See more at ",(0,n.jsx)(t.a,{href:"https://www.epj-conferences.org/articles/epjconf/abs/2019/19/epjconf_chep2018_03012/epjconf_chep2018_03012.html",children:"https://www.epj-conferences.org/articles/epjconf/abs/2019/19/epjconf_chep2018_03012/epjconf_chep2018_03012.html"}),"."]})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>s});var n=i(6540);const a={},o=n.createContext(a);function r(e){const t=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),n.createElement(o.Provider,{value:t},e.children)}}}]);